# Server
fastapi>=0.111.0
uvicorn[standard]>=0.30.0
pydantic>=2.6.0
pandas
# HTTP
aiohttp
requests>=2.31.0
asyncio
# ML inference
transformers>=4.44.0
peft>=0.12.0
sentencepiece>=0.1.99
safetensors>=0.4.3
# Torch is installed in Dockerfile with CUDA wheel

# Orchestration
langgraph>=0.2.30
langchain-openai>=0.2.0
langchain-groq>=0.2.0
langchain-community>=0.2.0
# Needed by TavilySearchResults tool
tavily-python>=0.3.6
RapidFuzz